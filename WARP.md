# WARP.md

This file provides guidance to WARP (warp.dev) when working with code in this repository.

## Project Overview

MCP Story Service is a narrative intelligence server that provides AI agents with comprehensive story analysis capabilities through the Model Context Protocol (MCP). It offers tools for story structure analysis, plot validation, consistency checking, genre pattern matching, and pacing analysis for AI movie production workflows.

## Common Development Commands

### Environment Setup
```powershell
# Install dependencies using Poetry
poetry install

# Activate virtual environment
poetry shell
```

### Running the Service
```powershell
# Start the MCP Story Service server
python -m src.mcp.server

# Alternative method
poetry run python -m src.mcp.server
```

### Testing
```powershell
# Run all tests
pytest

# Run specific test categories
pytest tests/unit/              # Unit tests
pytest tests/integration/       # Integration tests
pytest tests/contract/          # Contract tests
pytest tests/performance/       # Performance tests

# Run a single test file
pytest tests/unit/test_narrative_analyzer.py

# Run tests with verbose output
pytest -v

# Run tests with coverage
pytest --cov=src/
```

### Code Quality
```powershell
# Format code with Black
black src/ tests/

# Lint with Ruff
ruff check src/ tests/

# Fix linting issues
ruff check --fix src/ tests/

# Type checking with mypy
mypy src/
```

## Architecture Overview

### Core Components

**MCP Server (`src/mcp/server.py`)**
- Main entry point that initializes all dependencies and handlers
- Registers MCP tools and manages the server lifecycle
- Uses asyncio for concurrent request handling

**Handlers (`src/mcp/handlers/`)**
- Tool-specific handlers that implement MCP tool interfaces
- Each handler corresponds to a specific story analysis capability:
  - `story_structure_handler.py` - Three-act structure analysis
  - `plot_threads_handler.py` - Multi-episode plot tracking
  - `consistency_handler.py` - Narrative consistency validation
  - `genre_patterns_handler.py` - Genre-specific pattern application
  - `session_handler.py` - Project session management
  - `pacing_handler.py` - Tension curve and pacing analysis

**Services (`src/services/`)**
- Core business logic organized by domain:
  - `narrative/analyzer.py` - Story structure analysis engine
  - `consistency/validator.py` - Plot hole and timeline validation
  - `genre/analyzer.py` - Genre convention compliance checking
  - `pacing/calculator.py` - Tension curve calculation
  - `session_manager.py` - Redis-based session persistence

**Models (`src/models/`)**
- Data models representing story elements:
  - `story_session.py` - Session state and process isolation
  - `story_arc.py` - Three-act structure representation
  - `plot_thread.py` - Multi-episode narrative threads
  - `genre_template.py` - Genre-specific storytelling patterns
  - `narrative_beat.py` - Story pacing and tension points

**Library Components (`src/lib/`)**
- Shared utilities and infrastructure:
  - `redis_client.py` - Redis connection management
  - `genre_loader.py` - Genre configuration loading
  - `process_utils.py` - Process isolation utilities
  - `error_handler.py` - Error handling and recovery

### Key Architectural Patterns

**Process Isolation**: Each project runs in isolated context with independent sessions and analysis cache to prevent cross-project contamination.

**75% Confidence Threshold**: All analysis results must meet minimum quality standards. Results below threshold trigger recommendation workflows.

**Session Persistence**: Story analysis state persists across tool calls using Redis, enabling complex multi-step analysis workflows.

**Genre-Driven Analysis**: All analysis adapts to specific genre conventions (thriller, drama, comedy, etc.) for authentic storytelling recommendations.

## Development Patterns

### Adding New Analysis Tools

1. Create handler in `src/mcp/handlers/`
2. Implement service logic in appropriate `src/services/` domain
3. Define models in `src/models/` if needed
4. Register tool in `src/mcp/server.py`
5. Add contract tests in `tests/contract/`

### Working with Sessions

Always start analysis workflows with session creation:
```python
session = await session_handler.get_story_session({"project_id": "my-project"})
```

Sessions provide:
- Process isolation between projects
- Analysis result caching
- Persistence across tool calls
- Resource management and cleanup

### Quality Assurance

All analysis results include:
- `confidence_score`: Must be â‰¥ 0.75 for production use
- `meets_threshold`: Boolean indicating quality compliance
- `recommendations`: Actionable improvement suggestions

### Error Handling

The service implements graceful degradation:
- Malformed content returns partial results with reduced confidence
- Missing dependencies trigger specific error codes
- Session errors provide recovery instructions

## Testing Strategy

### Test Categories

**Unit Tests (`tests/unit/`)**
- Test individual components in isolation
- Mock external dependencies (Redis, file system)
- Focus on business logic correctness

**Contract Tests (`tests/contract/`)**
- Validate MCP tool interfaces and schemas
- Ensure API compatibility across versions
- Test parameter validation and response formats

**Integration Tests (`tests/integration/`)**
- Test complete workflows across multiple tools
- Validate session persistence and isolation
- Test error scenarios and recovery

**Performance Tests (`tests/performance/`)**
- Concurrent request handling
- Memory usage under load
- Response time benchmarks

### Running Focused Tests

```powershell
# Test specific functionality
pytest tests/unit/test_narrative_analyzer.py::test_analyze_story_structure
pytest tests/integration/test_story_structure_scenario.py
pytest tests/contract/test_session_tool.py
```

## Byterover MCP Integration

This project integrates with Byterover MCP tools for enhanced memory and knowledge management. Key workflows:

### Onboarding Workflow
1. Check handbook existence with `byterover-check-handbook-existence`
2. Create/update handbook using `byterover-create-handbook` or `byterover-update-handbook`
3. List and store modules with `byterover-list-modules` and `byterover-store-modules`
4. Store knowledge with `byterover-store-knowledge`

### Planning Workflow
1. Retrieve active plans with `byterover-retrieve-active-plans`
2. Save implementation plans with `byterover-save-implementation-plan`
3. Use `byterover-retrieve-knowledge` for each task
4. Update progress with `byterover-update-plan-progress`
5. Store results with `byterover-store-knowledge`

Always reference Byterover sources explicitly in responses with phrases like "According to Byterover memory layer" or "Based on memory extracted from Byterover."

## Configuration

### Genre Configuration
Genre templates are loaded from `config/genres/` directory. Each genre defines:
- Required story beats and conventions
- Pacing patterns and tension curves
- Character archetypes and relationships
- Authenticity validation rules

### Redis Configuration
Session persistence requires Redis server. Default connection assumes local Redis on standard port (6379).

### Quality Thresholds
- Minimum confidence score: 0.75
- Genre authenticity threshold: 0.75
- Narrative cohesion minimum: 0.75

## Dependencies

### Core Dependencies
- **Python 3.11+**: Required for modern async features
- **MCP**: Model Context Protocol implementation
- **Redis**: Session persistence and caching
- **pytest**: Testing framework
- **PyYAML**: Configuration file parsing

### Development Dependencies
- **Black**: Code formatting (line length: 88)
- **Ruff**: Fast Python linting
- **mypy**: Type checking
- **Poetry**: Dependency management

## Service Integration

### For AI Agents
- Use structured prompts to extract story elements
- Implement retry logic for low confidence scores
- Cache session IDs for project continuity
- Monitor confidence trends across iterations

### For Production Systems
- Implement proper error handling and timeouts
- Use connection pooling for high-volume requests
- Monitor service health and response times
- Set up automated quality gates based on confidence scores

The service handles up to 10 concurrent requests efficiently with complex analyses taking 2-3 seconds. Use appropriate timeouts (recommended: 10 seconds) and implement circuit breaker patterns for resilience.